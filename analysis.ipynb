{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udcca A retail company operates two stores: Store A in an urban area and Store B in a suburban area. The company wants to determine if there is a significant difference in average daily sales between the two locations to guide future investment and marketing strategies. The company collected a random sample of daily sales from each store in the last trimester.\n",
    "\n",
    "---\n",
    "\n",
    "| **Metadata** | **Details** |\n",
    "| :--- | :--- |\n",
    "| \ud83d\uddd3\ufe0f Generated | December 10, 2025 at 00:56 |\n",
    "| \ud83d\udcc1 Dataset | `Assignment data_06.xlsx` |\n",
    "| \ud83d\udccf Dimensions | 4 rows \u00d7 2 columns |\n",
    "| \ud83d\udee0\ufe0f Tool | Auto-Analysis App |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcd1 Table of Contents\n",
    "\n",
    "1. [Setup & Data Loading](#setup--data-loading)\n",
    "2. [\ud83d\udd27 Data Imputation](#data-imputation)\n",
    "3. [\u2699\ufe0f Normality Test](#normality-test)\n",
    "4. [\u2699\ufe0f Hypothesis Testing](#hypothesis-testing)\n",
    "5. [\ud83d\udcca Result Interpretation](#result-interpretation)\n",
    "\n---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Setup & Data Loading\n",
    "\n",
    "Import required libraries and load the preprocessed dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Required Libraries\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "\n",
    "# Set visual styling\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Load Dataset\n",
    "# ============================================================\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "print('=' * 50)\n",
    "print('\ud83d\udcca DATASET OVERVIEW')\n",
    "print('=' * 50)\n",
    "print(f'Rows:    {len(df):,}')\n",
    "print(f'Columns: {len(df.columns)}')\n",
    "print(f'Memory:  {df.memory_usage(deep=True).sum() / 1024:.1f} KB')\n",
    "print('=' * 50)\n",
    "\n",
    "df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd27 Data Imputation\n",
    "\n",
    "**Category:** `Preprocessing`\n",
    "\n",
    "> Replace missing values with mean imputation method\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Data Imputation\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Calculate the mean of available values for each column\n",
    "    mean_values = df.mean()\n",
    "\n",
    "    # Replace missing values with the calculated mean for each column\n",
    "    df_imputed = df.fillna(mean_values)\n",
    "\n",
    "    # Update the dataframe\n",
    "    df = df_imputed\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error in data imputation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u2699\ufe0f Normality Test\n",
    "\n",
    "**Category:** `Algorithm`\n",
    "\n",
    "> Apply Shapiro-Wilk normality test with alpha = 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Normality Test\n",
    "# ============================================================\n",
    "\n",
    "try:\n",
    "    from scipy import stats\n",
    "    import pandas as pd\n",
    "\n",
    "    # Apply the Shapiro-Wilk normality test to the imputed data for each store\n",
    "    normality_test_results = []\n",
    "    for column in df.columns:\n",
    "        if df[column].dtype.kind in 'bifc':  # Check if column is numeric\n",
    "            result = stats.shapiro(df[column].dropna())\n",
    "            normality_test_results.append((column, result.statistic, result.pvalue))\n",
    "        \n",
    "    # Interpret the test results\n",
    "    for column, statistic, pvalue in normality_test_results:\n",
    "        if pvalue < 0.05:\n",
    "            print(f\"{column} does not follow a normal distribution\")\n",
    "        else:\n",
    "            print(f\"{column} follows a normal distribution\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"Error in normality test: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u2699\ufe0f Hypothesis Testing\n",
    "\n",
    "**Category:** `Algorithm`\n",
    "\n",
    "> Perform t-test with alpha = 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Hypothesis Testing\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "def perform_t_test(df):\n",
    "    try:\n",
    "        # Formulate the null and alternative hypotheses\n",
    "        null_hypothesis = \"The average daily sales are equal between the two stores\"\n",
    "        alternative_hypothesis = \"The average daily sales are not equal between the two stores\"\n",
    "\n",
    "        # Apply the t-test to compare the average daily sales between the two stores\n",
    "        t_test_result = stats.ttest_ind(df['StoreA'].dropna(), df['StoreB'].dropna())\n",
    "\n",
    "        # Interpret the test results\n",
    "        alpha = 0.05\n",
    "        if t_test_result.pvalue < alpha:\n",
    "            print(f\"Reject the null hypothesis: {null_hypothesis}\")\n",
    "            print(f\"Accept the alternative hypothesis: {alternative_hypothesis}\")\n",
    "        else:\n",
    "            print(f\"Fail to reject the null hypothesis: {null_hypothesis}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in hypothesis testing: {e}\")\n",
    "\n",
    "# Example usage:\n",
    "# df = pd.DataFrame({\n",
    "#     'StoreA': [1, 2, 3, 4, 5],\n",
    "#     'StoreB': [6, 7, 8, 9, 10]\n",
    "# })\n",
    "# perform_t_test(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Result Interpretation\n",
    "\n",
    "**Category:** `Output`\n",
    "\n",
    "> Translate statistical findings into actionable insights\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Result Interpretation\n",
    "# ============================================================\n",
    "\n",
    "def translate_statistical_findings():\n",
    "    try:\n",
    "        # Summarize the key findings from the statistical analysis\n",
    "        print(\"Key Findings:\")\n",
    "        print(\"- Data imputation was performed using the mean method\")\n",
    "        print(\"- Normality tests were applied to each store's data\")\n",
    "        print(\"- Hypothesis testing was performed to compare average daily sales between the two stores\")\n",
    "        \n",
    "        # Discuss the implications of the findings for future investment and marketing strategies\n",
    "        print(\"Implications:\")\n",
    "        print(\"- The results of the hypothesis test can inform decisions on resource allocation and marketing strategies\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in result interpretation: {e}\")\n",
    "\n",
    "translate_statistical_findings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcdd Notes\n",
    "\n",
    "This notebook was automatically generated by **Auto-Analysis App**.\n",
    "\n",
    "- All code cells can be modified and re-executed\n",
    "- Visualizations are interactive in Jupyter environments\n",
    "- Results may vary based on data preprocessing applied\n",
    "\n",
    "---\n",
    "*Generated on 2025-12-10 00:56:28*\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}