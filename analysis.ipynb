{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Segmentation\\n",
    "\\n",
    "Generated by Auto-Analysis Web App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\\n",
    "Handle missing values and remove duplicates to ensure data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n# Drop duplicates\ndf = df.drop_duplicates()\n\n# Handle missing values (Simple Imputation)\nnumeric_cols = df.select_dtypes(include=['number']).columns\nfor col in numeric_cols:\n    df[col] = df[col].fillna(df[col].median())\n    \n# Fill categorical missing values with mode\ncat_cols = df.select_dtypes(include=['object', 'category']).columns\nfor col in cat_cols:\n    df[col] = df[col].fillna(df[col].mode()[0])\n        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering: RFM\\n",
    "Create Recency, Frequency, and Monetary value features from transaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n# Identify columns (Heuristic)\ndate_col = [c for c in df.columns if 'date' in c.lower() or 'time' in c.lower()][0]\namount_col = [c for c in df.columns if 'amount' in c.lower() or 'price' in c.lower() or 'spend' in c.lower()][0]\nid_col = [c for c in df.columns if 'id' in c.lower() or 'customer' in c.lower()][0]\n\n# Convert to datetime\ndf[date_col] = pd.to_datetime(df[date_col])\n\n# Calculate RFM\nsnapshot_date = df[date_col].max() + pd.Timedelta(days=1)\nrfm = df.groupby(id_col).agg({\n    date_col: lambda x: (snapshot_date - x.max()).days,\n    id_col: 'count',\n    amount_col: 'sum'\n}).rename(columns={\n    date_col: 'Recency',\n    id_col: 'Frequency',\n    amount_col: 'Monetary'\n})\ndf = rfm # Switch to RFM dataframe for clustering\n            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Scaling\\n",
    "Normalize features using StandardScaler to ensure equal weighting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\nfrom sklearn.preprocessing import StandardScaler\n\n# Select numeric features for clustering\nX = df.select_dtypes(include=['number'])\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA (Dimensionality Reduction)\\n",
    "Reduce dimensions to 2 components for visualization and noise reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\ndf['PCA1'] = X_pca[:, 0]\ndf['PCA2'] = X_pca[:, 1]\n        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering\\n",
    "Segment data into clusters using K-Means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\nfrom sklearn.cluster import KMeans\n\n# Determine optimal clusters (simplified for now, fixed to 3)\nkmeans = KMeans(n_clusters=3, random_state=42)\ndf['Cluster'] = kmeans.fit_predict(X_scaled)\n        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Visualization\\n",
    "Visualize clusters using PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='PCA1', y='PCA2', hue='Cluster', data=df, palette='viridis')\nplt.title('Customer Segments (PCA)')\nplt.show()\n        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Analysis Step\\n",
    "Describe your new analysis step here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your python code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}